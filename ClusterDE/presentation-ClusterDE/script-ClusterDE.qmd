---
title: "ClusterDE Presentation Script"
author: Carson Zhang
abstract: |
  In typical differential expression analysis, a clustering algorithm is applied 
  to scRNA-seq data, and then a differential expression test is conducted 
  in order to identify genes that are differentially expressed between the clusters.
  However, this procedure constitutes "double dipping", as it first clusters
  the data to identify cell types, and then uses those same clusters to identify 
  cell-type marker genes. This leads to an inflated FDR for DE genes. 
  Song et al. (2023) propose ClusterDE, a post-clustering DE method that 
  controls the FDR of DE genes. ClusterDE generates a synthetic null dataset
  that preserves the structure of the real data, 
  computes differences between this null dataset and the real data, then performs 
  FDR control on the results. Simulations and real data analysis demonstrate
  that ClusterDE controls the FDR and identifies cell-type marker genes as
  top DE genes, successfully distinguishing them from housekeeping genes.
format:
  html:
    toc: true
    html-math-method: katex
    embed-resources: true
  # typst:
  #   toc: true
  #   section-numbering: 1.1.a
  #   columns: 1
  #   mainfont: "Arial"
  #   fontsize: 11pt
  #   keep-typ: true
---

# Introduction

## Outline

### What is the analysis goal?

For context, which type of scRNA-seq analysis do we ultimately want to do?

### What are the problems with existing methods?

Why are obvious, natural approaches to differential expression analysis inadequate?

### How does ClusterDE solve them?

Explanation of the method.

### Does ClusterDE really solve them?

Compare ClusterDE's performance against other methods on real datasets.

### What are other ideas that might (not) work to solve these?

Consider potential modifications to the ClusterDE method.

## Background

We want to identify cell-type marker genes. We will use these to identify cell types.

TODO: add motivation for cell type identification.

TODO: define and add motivation for identifying cell-type marker genes.

TODO: add the count matrix.

## Double-dipping: the problem with naive methods

TODO: add the notation for the theory: basically, since clustering is imperfect, theory tells us that even if our decision is correct wrt the clusters, it may not be correct wrt the true cell type.

A natural way to do this might look like this.

- Cluster the sample. We hope that each cluster represents a distinct cell type.
- For each gene, perform a hypothesis test comparing its expression levels between the two clusters.

## Why testing after clustering is problematic

However, this leads to double-dipping because we used the data twice.

1. First, we clustered the cells.  The algorithm chose these two specific clusters because, in some sense, these two subsets of cells look the most different in terms of their gene expression levels. That is, the algorithm found variation in gene expression levels that drove this particular clustering.

2. Next, we test each gene to see how different the expression levels are between the two clusters. However, we already know that this variation is there: that's how we got the clusters in the first place. So we are testing for variation that we already found through clustering, and therefore, we will find differentially expressed genes when we shouldn't.

When we cluster a sample of a single cell type into two clusters, we cluster based on differences in gene expression that occurred due to random noise. This means we forced the genes to exhibit different distributions in the two clusters, so we are likely to find this forced variation instead of true variation in the dataset.

## Double-dipping example

![Figure S16](figures/S16.jpg)

This is illustrated in the above example. We forced the genes to have different distributions between the clusters (in this clustering, cluster 1 has significantly higher expression levels for both genes). Therefore, our tests are significant.

# Method

## ClusterDE method: 4 steps

In words, the ClusterDE method can be broken up into four steps:

1. Generate a synthetic null dataset that mimics the structure 
(in particular, the gene-gene correlation structure) of the original data.

2. Separately partition the synthetic null data and the target data (real data) into two clusters.

3. Separately for the null and target data, perform hypothesis tests for differentially expressed genes between the two clusters. 
For each gene, compute some sort of difference between the p-values on the two datasets.

4. Output a subset of the significant results from step 3 as potential cell-type marker genes.

## ClusterDE

![A graphical illustration of ClusterDE.](figures/ClusterDE_illustration.png)

It is important to note that ClusterDE "does not provide an automatic decision about whether two clusters should be merged". Its outputs are potential DE genes, and therefore it does not directly measure the quality of a given clustering. These potential cell-type marker genes enable researchers to gain biological insights into the clusters, and they empower researchers to further explore the functional and molecular characteristics of the clusters.

## 1. Synthetic null generation

The synthetic null generation consists of three steps, as described in the following figure.

![Null generation steps.](figures/ClusterDE_supp_null_generation.png)

#### 1. Model the null distribution in terms of the Gaussian copula.

TODO: [explain the probability integral transform](https://blog.carsonzhang.com/posts/probability_integral_transform/).

To do this, we will need Sklar's Theorem.

## Sklar's Theorem

**Theorem** (Sklar's Theorem): Let $\mathbf{X}$ be a $m$-dimensional random vector with joint cumulative distribution function $F$ and marginal distribution functions $F_j, j = 1, ..., m$. The joint CDF can be expressed as 

$$
F(x_1, ..., x_m) = C(F_1(x_1), ..., F_m(x_m))
$$

with associated probability density (or mass) function

$$
f(x_1, ..., x_m) = c(F_1(x_1), ..., F_m(x_m)) f_1(x_1) ... f_m(x_m)
$$

for a $d$-dimensional copula $C$ with copula density $c$. 

The inverse also holds: the copula corresponding to a multivariate CDF $F$ with marginal distribution functions $F_j, j = 1, ..., m$ can be expressed as 

$$
C(u_1, ..., u_m) = F(F_1^{-1}(u_1), ..., F_m^{-1}(u_m))
$$
, and the copula density (or mass) function is 

$$
c(u_1,...,u_m) = \frac{f(F_1^{-1}(u_1), ..., F_m^{-1}(u_m))}
  {f_1(F_1^{-1}(u_1)) ... f_m(F_m^{-1}(u_m))}
$$
.

## Why Sklar's Theorem?

Sklar's Theorem allows us to choose $C$, the specific copula function that we will use to approximate $F$. 
For convenience, we will choose $C$ to be a multivariate Gaussian distribution, since we know how to sample from it.
Therefore, we have found a way to estimate the joint MVNB distribution of genes.

$$
C(\mathbf{u}; \mathbf{R}) = \Phi_{\mathbf{R}}(\Phi^{-1}(u_1), ..., \Phi^{-1}(u_m))
$$

Now, our goal is to estimate the parameters ${\mu_j, \sigma_j}_{j = 1}^m$ and $\mathbf{R}$. 

## 2. Fit the null model to the real data.

Recall that the power of the copula is that it allows us to consider the marginal distributions separately from the covariance structure. Therefore, we can proceed as follows.

For each gene $j$, estimate $\{\mu_j, \sigma_j\}$ using maximum likelihood. These are the marginal distributions.

## 2. (cont.)

Separately, use the Gaussian copula to model the dependence structure.

- Transform the raw data (counts) to the CDF values of the counts. 
  Given the parameters for each marginal distribution that we just generated, 
  compute the CDFs specified by those parameters.
- Transform the discrete CDF values into continuous $U(0, 1)$ variables.
  Do this by computing $U_{ij} = V_{ij} \hat{F}_j (Y_{ij}) + (1 - V_{ij}) \hat{F}_j (Y_{ij})$.
- Transform the CDF values to standard Gaussian random variables.
  That is, compute $\Phi^{-1}(U_{ij})$ for each $j = 1, .., m$.
- Fit a $m$-dimensional multivariate Gaussian distribution to this data to compute $\mathbf{\hat{R}}$.
  $\mathbf{\hat{R}}$ is the sample correlation matrix of this data.
  
#### 3. Sample from the fitted null model.
- Generate a sample of size $n$ from $N_m(\mathbf{0}, \mathbf{\hat{R}})$. (Denote them as $\tilde{Z}_{ij}$ because each is standard Gaussian.)

$$
\begin{bmatrix} 
    \tilde{Z}_{11} & \dots & \tilde{Z}_{1m} \\
    \vdots & \ddots & \\
    \tilde{Z}_{n1} &        & \tilde{Z}_{nm}
\end{bmatrix}
$$

- Convert them to negative binomial count vectors. First we apply the marginal CDFs to transform them to $U(0, 1)$ random variables. Then, we apply the inverse of each negative binomial CDF to transform them to the proper counts (negative binomial random variables) for the corresponding gene.

$$
\begin{bmatrix} 
    \hat{F}_1^{-1}(\Phi(\tilde{Z}_{11})) & \dots & \hat{F}_m^{-1}(\Phi(\tilde{Z}_{1m})) \\
    \vdots & \ddots & \\
    \hat{F}_1^{-1}(\Phi(\tilde{Z}_{n1})) &        & \hat{F}_m^{-1}(\Phi(\tilde{Z}_{nm}))
\end{bmatrix}
$$

## 2. Clustering

ClusterDE allows any clustering algorithm. Note that it only handles the case of two clusters, so if you started out with more clusters, you should identify a particular pair of interest. In the **Practical guidelines for ClusterDE usage** subsection, steps 1 and 2 describe how an analyst should proceed.

1. Given $\geq 2$ clusters, identify 2 clusters of interest. Generally, this will be a pair for which you suspect the clustering is spurious (i.e. you think the two clusters actually come from the same cell type, so they are strong candidates to be merged into a single cluster).

2. Filter the data so that you only consider the subset of cells that come from those two clusters.

## Clustering algorithms

#### UMAP

UMAP is common in scRNA-seq analysis.

TODO: summarize UMAP.

#### Louvain

The example analyses in the presentation use the default Seurat clustering procedure, which uses the Louvain algorithm.

TODO: describe the Seurat clustering pipeline.

TODO: summarize the Louvain algorithm.

## 3. DE analysis (testing)

ClusterDE allows any DE test. 

TODO: choose and summarize a common DE test(s), e.g. Wilcoxon, since it performs well when analyzing a homogeneous sample.

Let $P_1, ..., P_m$ be the p-values computed by the $m$ DE tests on the target data. 

ClusterDE allows any summary statistic $t$ and computes the contrast score as:

$$C_j = t(\text{target data}) - t(\text{synthetic null data})$$

However, the authors propose the following $t$.

Define the target DE score $S_j := -\log_{10}P_j$. Likewise for the synthetic null data.

Motivation for this formula: it is extremely similar to the $S$-value.

$$
S = -\log_2(P)
$$

This is exactly the information content of the observed p-value, i.e. how surprising the p-value was. So, the difference in S-values can be thought of as how much more surprising the target test re sult was than the null test result.

Under $H_0$, this will satisfy symmetry, one of the requirements for the FDR control method. This is because, if the null hypothesis is true, neither dataset should systematically contain more DE genes than the other.

The final outputs of step 3: $m$ target DE scores $S_1, ..., S_m$; $m$ null DE scores $\tilde{S}_1, ..., \tilde{S}_m$.

## 4. FDR control

Given the target and null DE scores, compute a contrast score for gene $j$ as $C_j := S_j - \tilde{S}_j$.

In reality, we will have some more positive contrast scores than negative ones.

In the case that there truly are two cell types, then we should definitely expect some true DE genes, and should therefore expect more positive contrast scores than negative ones. 

Recall the contrast score formula: $C_j := S_j - \tilde{S}_j$. When this is positive, then the DE test on the target data was more surprising under the null, which means it outputted a smaller p-value. This *should* be the case if the null is false. This is why the authors say that, ideally, slightly less than 50% of all genes' contrast scores should be negative: sometimes, the null is false, and when that is the case, we will see additional values in the right tail (and only in the right tail) of the contrast score distribution.

<!-- We want to satisfy the symmetry requirement of Clipper. This is analogous to the uniform p-value assumption in other hypothesis tests.    -->

![FDR control.](figures/ClusterDE_illustration-fdr_control.png){width=50%}

Motivation for the cutoff: under the null hypothesis, we have a symmetric distribution of contrast scores. Assume the negative tail is differences due to random noise. Under the null hypothesis, the right tail would be the same size. 

Our real right tail will be bigger (we hope), since there are true differentially expressed genes which we will discover. And each of these will appear in the right tail. So any instances where the null is violated will appear only in the right tail.

Our contrast score cutoff is:

$$
t* = \min\left\{t \in \{|C_j|: C_j \neq 0\}: \frac{1+\#\{j:C_j \leq -t\}}{\#\{j:C_j \geq t\} \lor 1} \leq q\right\}
$$

We choose the minimum $t$ to maximize our discoveries, i.e. to "use" all of the false discoveries that we can.

## Results

### Cell line analysis: no DE genes

### PBMC dataset: meaningful DE genes

TODO: choose and describe example analyses from the paper.

TODO: describe an example analysis on a homogeneous sample: ideally, identify 0 DE genes.

## Cell line analysis

A cell line is a homogeneous 

TODO: describe an example analysis on a sample with known cell types: ideally, identify biologically meaningful DE genes.

## 

## Alternative strategies for synthetic null generation

Generating the synthetic null dataset as described earlier preserves more of the original structure of the data.

Generating the synthetic null dataset as described earlier preserves more of the original structure of the data, compared to using knockoffs or permuting the genes.

TODO: describe knockoffs.

TODO: describe gene permutation.

![Comparison of synthetic null generation strategies.](figures/S7.png)

## Alternatives for controlling FDR

TODO: write up explanations for all of these

### Things that work

- Applying a multiple testing correction procedure (e.g. Benjamini-Hochberg), determine which null hypotheses to reject: which genes you will say are differentially expressed.

### Things that work sometimes

- Count splitting: sample gene counts to create two datasets

### Things that don't work

- Splitting the data

## Appendix

## Biology

TODO: decide which of the following biology background is necessary to include in the presentation.

### RNA

RNA carries the genetic information specific in DNA. There are two main types of RNA.

**Non-coding RNA** performs some biological function.

**Messenger RNA** forms a template for protein production (it codes for a protein which performs some biological function).

TODO: explain the jump from RNA to the UMI count matrix.

TODO: define UMI.

### scRNA-seq

TODO: give an explanation of scRNA-seq data collection and analysis.
